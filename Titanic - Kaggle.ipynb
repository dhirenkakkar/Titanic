{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.style.use('ggplot')\nsns.set(style=\"darkgrid\")\n%config InlineBackend.figure_format = 'retina'\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Overview"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train shape: ' + str(train.shape))\nprint('Test shape: ' + str(test.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (train.info())\nprint('_'*40)\nprint (test.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA, data cleaning and feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots()\nsns.countplot('Survived', data=train)\nax.set_title('Passengers survived')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots()\nsns.countplot('Pclass', hue='Survived', data=train)\nax.set_title('Survived over Pclass')\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False)['Survived'].agg({'Survived': ['mean','count']})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots()\nsns.countplot('Sex', hue='Survived', data=train)\nax.set_title('Survived over sex')\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False)['Survived'].agg({'Survived': ['mean','count']})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax=sns.kdeplot(train.loc[(train['Survived'] == 0),'Age'] , color='gray',shade=True,label='Not survived')\nax=sns.kdeplot(train.loc[(train['Survived'] == 1),'Age'] , color='g',shade=True, label='Survived')\n\nplt.xlabel(\"Age\")\nplt.ylabel('% Survived')\nplt.title('Survived over age')\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='Sex', hue='Pclass', col=\"Survived\", data=train, kind='count', height=5, aspect=.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots()\nsns.countplot('SibSp', hue='Survived', data=train)\nax.set_title('Survived over SibSp')\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[[\"SibSp\", \"Survived\"]].groupby(['SibSp'], as_index=False)['Survived'].agg({'Survived': ['mean','count']})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots()\nsns.countplot('Parch', hue='Survived', data=train)\nax.set_title('Survived over Parch')\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[[\"Parch\", \"Survived\"]].groupby(['Parch'], as_index=False)['Survived'].agg({'Survived': ['mean','count']})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding family features\ndef getFamilySize(row):\n    return row[\"SibSp\"] + row[\"Parch\"] + 1\n\ndef getIsAlone(row):\n    if row['FamilySize'] == 1:\n        return 1\n    return 0\n\ndef fam_size(train, test):\n    for i in [train, test]:\n        i['FamilySize'] = i.apply(getFamilySize, axis=1)\n        i['IsAlone'] = i.apply(getIsAlone, axis=1)\n        \n        i['FamilyType'] = np.where((i['SibSp']+i['Parch']) == 0 , 'Solo',\n                           np.where((i['SibSp']+i['Parch']) <= 3,'Nuclear', 'Big'))\n        del i['SibSp']\n        del i['Parch']\n    return train, test\n\ntrain, test = fam_size(train, test)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots()\nsns.countplot('FamilySize', hue='Survived', data=train)\nax.set_title('Survived over FamilySize')\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[[\"FamilySize\", \"Survived\"]].groupby(['FamilySize'], as_index=False)['Survived'].agg({'Survived': ['mean','count']})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots()\nsns.countplot('IsAlone', hue='Survived', data=train)\nax.set_title('Survived over IsAlone')\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[[\"IsAlone\", \"Survived\"]].groupby(['IsAlone'], as_index=False)['Survived'].agg({'Survived': ['mean','count']})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding name features\ndef names(train, test):\n    for i in [train, test]:\n        i['NameLen'] = i['Name'].apply(lambda x: len(x))\n        i['NameTitle'] = i['Name'].apply(lambda x: x.split(',')[1]).apply(lambda x: x.split()[0])\n        del i['Name']\n    return train, test\n\n\ntrain, test = names(train, test)\npd.crosstab(train['NameTitle'], train['Sex'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[[\"NameTitle\", \"Age\"]].groupby(['NameTitle'], as_index=False).mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filling missing age data\ndef age_impute(train, test):\n    for i in [train, test]:\n        i['Age_Flag'] = i['Age'].apply(lambda x: 1 if pd.isnull(x) else 0)\n        data = train.groupby(['NameTitle', 'Pclass'])['Age']\n        i['Age'] = data.transform(lambda x: x.fillna(x.mean()))\n    return train, test\n\ntrain, test = age_impute(train, test)\n\ntrain.info()\nprint('_'*40)\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding cabin features\ndef cabin(train, test):\n    for i in [train, test]:\n        i['ExistCabin'] = i.apply(getCabinKind, axis=1)\n        i['CabinLetter'] = i['Cabin'].apply(lambda x: str(x)[0])\n        del i['Cabin']\n    return train, test\n\n\ndef cabin_num(train, test):\n    for i in [train, test]:\n        i['Cabin_num1'] = i['Cabin'].apply(lambda x: str(x).split(' ')[-1][1:])\n        i['Cabin_num1'].replace('an', np.NaN, inplace = True)\n        i['Cabin_num1'] = i['Cabin_num1'].apply(lambda x: int(x) if not pd.isnull(x) and x != '' else np.NaN)\n        i['Cabin_num'] = pd.qcut(train['Cabin_num1'],3)\n    train = pd.concat((train, pd.get_dummies(train['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n    test = pd.concat((test, pd.get_dummies(test['Cabin_num'], prefix = 'Cabin_num')), axis = 1)\n    del train['Cabin_num']\n    del test['Cabin_num']\n    del train['Cabin_num1']\n    del test['Cabin_num1']\n    return train, test\n\ndef getCabinKind(row):\n    cabin = row['Cabin']\n    if cabin == cabin:\n        return 1\n    return 0\n    \ntrain, test = cabin_num(train, test)\ntrain, test = cabin(train, test)\n\nf, ax = plt.subplots()\nsns.countplot('ExistCabin', hue='Survived', data=train)\nax.set_title('Survived over ExistCabin')\nplt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filling missing embarked data\ndef embarked_impute(train, test):\n    for i in [train, test]:\n        i['Embarked'] = i['Embarked'].fillna('S')\n    return train, test\n\ntrain, test = embarked_impute(train, test)\ntest['Fare'].fillna(train['Fare'].mean(), inplace = True)\n\ntrain.info()\nprint('_'*40)\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding ticket features\ndef ticket_grouped(train, test):\n    for i in [train, test]:\n        i['TicketLetter'] = i['Ticket'].apply(lambda x: str(x)[0])\n        i['TicketLetter'] = i['TicketLetter'].apply(lambda x: str(x))\n        i['TicketLetter'] = np.where((i['TicketLetter']).isin(['1', '2', '3', 'S', 'P', 'C', 'A']), i['TicketLetter'],\n                                   np.where((i['TicketLetter']).isin(['W', '4', '7', '6', 'L', '5', '8']),\n                                            'LowTicket', 'OtherTicket'))\n        i['TicketLen'] = i['Ticket'].apply(lambda x: len(x))\n        del i['Ticket']\n    return train, test\n\ntrain, test = ticket_grouped(train, test)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'Ticket_Lett', 'Cabin_Letter', 'Name_Title', 'Fam_Size']):\n    for column in columns:\n        train[column] = train[column].apply(lambda x: str(x))\n        test[column] = test[column].apply(lambda x: str(x))\n        good_cols = [column+'_'+i for i in train[column].unique() if i in test[column].unique()]\n        train = pd.concat((train, pd.get_dummies(train[column], prefix = column)[good_cols]), axis = 1)\n        test = pd.concat((test, pd.get_dummies(test[column], prefix = column)[good_cols]), axis = 1)\n        del train[column]\n        del test[column]\n    return train, test\n\nPassengerId_copy = test['PassengerId']\n\ndef drop(train, test, bye = ['PassengerId', 'FamilySize', 'IsAlone', 'ExistCabin']):\n    for i in [train, test]:\n        for z in bye:\n            del i[z]\n    return train, test\n\ntrain, test = dummies(train, test, columns = ['Pclass', 'Sex', 'Embarked', 'TicketLetter', 'CabinLetter', 'NameTitle', 'FamilyType'])\ntrain, test = drop(train, test)\n\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"rf_model = RandomForestClassifier(bootstrap=True, criterion='gini', max_depth=10,\n                                  max_features=3, max_leaf_nodes=None,\n                                  min_impurity_decrease=0.0, min_impurity_split=None,\n                                  min_samples_leaf=1, min_samples_split=4,\n                                  min_weight_fraction_leaf=0.0, n_estimators=1500,\n                                  n_jobs=None, oob_score=True, random_state=42, verbose=0,\n                                  warm_start=False)\n\nrf_model.fit(train.iloc[:, 1:], train.iloc[:, 0]) \nprint(\"Random forest score: \" + \"%.4f\" % rf_model.oob_score)\n\npd.concat((pd.DataFrame(train.iloc[:, 1:].columns, columns = ['variable']), \n           pd.DataFrame(rf_model.feature_importances, \n                        columns = ['importance'])), axis = 1).sort_values(by='importance', ascending = False)[:20]"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"#random forest model\n\n\nrf = RandomForestClassifier(max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\n\nparam_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10],\n              \"min_samples_split\" : [2, 4, 10, 12, 16], \"n_estimators\": [50, 100, 400, 700, 1000]}\ngs = GridSearchCV(estimator=rf, param_grid=param_grid, scoring='accuracy', cv=3, n_jobs=-1)\ngs = gs.fit(train.iloc[:, 1:], train.iloc[:, 0])"},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit the model\nrf = RandomForestClassifier(criterion='gini', n_estimators=1500, max_depth=10, min_samples_split=4 ,\n                             min_samples_leaf=1, max_features='auto', oob_score=True, random_state=1, n_jobs=-1)\nrf.fit(train.iloc[:, 1:], train.iloc[:, 0])\nprint(\"%.4f\" % rf.oob_score_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#variable importance\npd.concat((pd.DataFrame(train.iloc[:, 1:].columns, columns = ['variable']), \n           pd.DataFrame(rf.feature_importances_, columns = ['importance'])), \n          axis = 1).sort_values(by='importance', ascending = False)[:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#prediction\npredictions = rf.predict(test)\npredictions = pd.DataFrame(predictions, columns=['Survived'])\npredictions = pd.concat((PassengerId_copy, predictions), axis = 1)\npredictions.to_csv('random_forest_model.csv', sep=\",\", index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}